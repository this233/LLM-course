1. 2018.06 GPT-1 
    - Decoder-only架构
    - **生成式预训练**

2. 2019.02 GPT-2
    - 预训练**数据集扩大**
    - 模型**参数量扩大**（**0.12B -> 1.5B**）

3. 2020.05 GPT-3
    - **In-context Learning** 
    - **大幅增加**参数量（**1.5B -> 175B**）

4. 2022.03 GPT-3.5
    - 指令跟随（SFT）
    - 人类对齐（RLHF）


5. 2023.03 GPT-4
    - **图文输入**-文本输出（GPT-4V）
    - 全面能力提升
    - 【注】2022.11 ChatGPT = GPT-3.5 + GPT4


#### GPT-4 2023.03
##### 功能
在日常对话中，GPT‑3.5 和 GPT‑4 之间的区别可能并不明显。但**当任务复杂度达到一定阈值时，差异便会显现出来** — GPT‑4 更为可靠、更具创造性，而且能够处理比 GPT‑3.5 更加细致入微的指令。

为了解这两款模型之间的差异，我们基于各类基准对两者进行了测试，包括模拟人类考试。我们采用最新公开的试题（对于奥林匹克竞赛和进阶先修课程 (AP) 自由回答题），或者购买 2022–2023 年版模拟试卷。我们没有就这些考试对模型进行专门的训练。虽然模型在训练过程中接触过少数考试题目，但我们相信测试结果仍具有代表性 — 详情请参阅我们的技术报告⁠（在新窗口中打开）。

##### 视觉输入
**GPT‑4 能够接受文本和图片形式的提示**，与纯文本提示类似，用户可借此指定任何视觉或语言任务。具体而言，它能根据图文混合输入内容产生文本输出（如自然语言、代码等）。
在多个领域（包括含有文本与照片、图表或截图的文档），GPT‑4 展现出与处理纯文本相似的性能。
此外，它还能与专为纯文本语言模型开发的测试时间技术结合使用，包括少样本提示和思维链⁠（在新窗口中打开）提示。目前，*图片输入功能仍处于研究预览阶段*，尚未向公众开放。

##### 可控性
我们一直在全面推进我们在主题文章定义 AI 行为⁠中概述的计划，其中包括可控性。与具有固定冗长度、语调和风格的经典 ChatGPT 不同，开发人员（以及不久后的 ChatGPT 用户）现在可以通过在“系统”消息中指明方向，来指定 AI 的风格和任务。API 用户可利用系统消息在界限内⁠（在新窗口中打开）大幅定制用户体验。我们将持续改进这项功能（尤其是，我们知道系统消息是当前模型最简单的“越狱”方式，换言之，界限的遵循情况并不完美），但我们鼓励您尝试使用并告知我们您的想法。

##### 局限性
尽管 GPT‑4 能力出众，但它仍与早期 GPT 模型存在类似的局限性。最重要的是，它仍不完全可靠（会“虚构”事实并出现推理错误）。在使用语言模型输出时，尤其是在高风险场景下，必须格外谨慎，具体方案（如人工审核、结合额外背景进行验证或干脆避免在高风险场景中使用）应与特定用例的需求相匹配。

与之前的模型相比，GPT‑4 在“虚构事实”方面已有显著改善（之前的模型也在每次迭代中逐步完善），但依然是个现实存在的问题。在我们内部的对抗性事实性评估中，GPT‑4 的得分比最新版 GPT‑3.5 高出 40%：

##### 风险与缓解
从训练伊始，我们便不断对 GPT‑4 进行迭代优化，以提升其安全性与一致性。相关工作涵盖预训练数据的选择与筛选、评估与专家参与、模型安全改进，以及监控与执行等方面。

GPT‑4 存在与先前模型类似的风险，例如生成有害建议、含漏洞的代码或不准确的信息。然而，GPT‑4 的新增功能也带来了新的风险点。为了解这些风险的范围和程度，我们邀请了 AI 对齐风险、网络安全、生物风险、信任与安全以及国际安全等领域的 50 多位专家，对模型进行了对抗性测试。利用他们的研究发现，我们在需要运用专业知识进行评估的高风险领域，对模型行为进行了测试。来自这些专家的反馈和数据，为模型的风险缓解和优化改进提供了素材。例如，我们收集了额外数据，帮助 GPT‑4 更好地拒绝有关如何合成危险化学品的请求。

**在 RLHF（基于人类反馈的强化学习）训练过程中，GPT‑4 引入了额外的安全奖励信号**，以减少有害输出（参见使用指南⁠（在新窗口中打开）中的定义），具体而言，训练模型拒绝有关此类内容的请求。该奖励信号由一个 GPT‑4 零样本分类器提供，用于判断安全相关提示的安全界限和完成风格。为防止模型拒绝正当请求，我们从多个来源（如经标注的生产数据、人类红队测试、模型生成的提示）收集多样化的数据集，并在允许和禁止的类别同时应用安全奖励信号（具有正值或负值）。 

与 GPT‑3.5 相比，我们的缓解措施显著提升了 GPT‑4 的许多安全特性。与 GPT‑3.5 相比，我们已将模型响应禁止内容请求的倾向降低了 82%，并且 GPT‑4 对敏感请求（如医疗建议和自我伤害）的响应更符合我们的政策，合规率提高了 29%。

总体而言，我们在模型层面的干预措施增加了引发不良行为的难度，但这种行为仍有可能发生。此外，仍存在一些“越狱”方法，能够生成违反我们使用指南⁠的内容。随着 AI 系统“每令牌风险”的增加，在这些干预措施中实现极高的可靠性将变得至关重要。目前而言，需要结合部署时的安全技术（如滥用监控）来弥补这些局限性，这点很重要。

GPT‑4 及其后续模型有可能对社会产生重大影响，这些影响可能是有益的，也可能是有害的。我们正与外部研究人员合作，改进我们了解和评估潜在影响的方法，并为未来系统中可能出现的危险功能构建评估体系。关于 GPT‑4 及其他 AI 系统带来的潜在社会和经济影响，我们近期将与大家分享我们的更多思考。

##### 训练过程
与之前的 GPT 模型一样，GPT‑4 基础模型经过训练，可以预测文档中的下一个词语，而训练所用的是公开可得的数据（如互联网数据）以及经我们授权的数据。这些数据构成了一个网络规模的语料库，其中包括或正确或错误的数学题解答、或强或弱的推理、或矛盾或一致的陈述，并且代表了各种各样的意识形态和思想。

因此，当被提示问题时，基础模型可能以多种方式回答，其中一些方式可能与用户意图相去甚远。为使模型在规则之内作出与用户意图一致的回答，我们使用基于人类反馈的强化学习 (RLHF⁠) 对模型行为进行了微调。

**需要注意的是，模型的能力似乎主要源于预训练过程 — RLHF 并不能提升模型在考试中的表现（若非主动干预，性能实际上还有所降低）。**
**但模型的控制则源于后训练过程 — 基础模型甚至需要借助提示工程才知道它应该回答问题。**

##### 可预测的扩展
GPT‑4 项目的主要工作之一是，构建一个能够实现可预测扩展的深度学习技术栈。这样做的主要原因是，对于像 GPT‑4 这样的大规模训练任务，专门针对模型进行大量微调是不切实际的。我们开发了基础设施和优化方法，它们在多个规模下都表现出良好的可预测行为。为了验证这种可扩展性，我们**从使用相同方法但计算量减少 10,000 倍的模型进行外推，提前准确预测了 GPT‑4 在我们内部代码库（不属于训练集的一部分）上的最终损失**：

##### API
*GPT‑4 的上下文长度为 8,192 令牌。我们还有限开放上下文长度为 32,768（约 50 页文本）的版本 gpt-4-32k*，该版本未来也会自动更新（当前版本为 gpt-4-32k-0314，同样支持至 6 月 14 日）。使用定价为每 1K 提示令牌 0.06 美元，每 1K 补全令牌 0.12 美元。我们仍在改进模型处理较长上下文的质量，欢迎您就该模型在您用例中的表现提供宝贵的反馈。我们会根据容量以不同的速率处理 8K 和 32K 引擎的请求，因此您可能会在不同时间获得它们的访问权限。

#### GPT-4 Turbo 2023.11
- 上下文对话长度：GPT4最大只能支持**8k的上下文长度**（约等于6000个单词），而GPT-4 Turbo则具有**128k上下文长度**，以一篇文章约1k字计算，GPT-4 Turbo可同时处理128篇文章。
- 模型控制：GPT-4 Turbo采用全新模型控制技术，使开发者可以更精细地调整模型输出，提升用户体验。
- 知识库更新：GPT-4 Turbo的现实世界知识截止时间现在是**2023年4月**，而GPT-4的截止时间为2021年9月。
- 多模态API：文生图模型DALL·E 3、具有视觉输入能力的GPT-4 Turbo以及新的声音合成模型（TTS）都已进入API。
- 定制微调：OpenAI允许开发人员创建ChatGPT自定义版本，包括修改模型训练过程，进行额外的特定领域预训练、运行针对特定领域定制的自定义强化学习后训练过程。
- 更低的价格和更高的限制：GPT-4 Turbo输入tokens价格仅为GPT-4的1/3，输出tokens价格是GPT-4的1/2；同时还将所有GPT-4付费用户的每分钟tokens限制增加了一倍。 [1]

#### GPT-4o(omni) 2024.05 
- **自回归全模态模型**
- 接受文本、音频、图像和视频的任意组合作为输入
- 生成文本、音频和图像输出的任意组合

GPT‑4o（“o”代表“omni”）标志着我们**朝着更自然的人机交互迈出的又一步——它能够接受文本、音频、图像和视频的任意组合作为输入，并生成文本、音频和图像输出的任意组合。**
它可以在最短 232 毫秒（平均 320 毫秒）内对音频输入作出响应，这已接近于在对话中的人类响应时间⁠（在新窗口中打开）。
在对英语文本和代码的处理方面，它的性能可以媲美 GPT‑4 Turbo，而对非英语语言的文本的处理也有显著改进，同时 API 也更快且价格低 50%。与现有模型相比，GPT‑4o 在对视觉内容和音频的理解方面尤其出色。

##### 1 引言
GPT‑4o 是一种**自回归全模态模型**，它能够接受文本、音频、图像和视频的任意组合作为输入，并生成文本、音频和图像输出的任意组合。
经过我们的训练，它可以在文本、视觉内容和音频之间实现端到端转换，这意味着所有输入和输出都由同一个神经网络处理。 

GPT‑4o 可以在最短 232 毫秒（平均 320 毫秒）内对音频输入作出响应，这已接近于在对话中的人类响应时间。在对英语文本和代码的处理方面，它的性能可以媲美 GPT‑4 Turbo，而对非英语语言的文本的处理也有显著改进，同时 API 也更快且价格低 50%。与现有模型相比，GPT‑4o 在对视觉内容和音频的理解方面尤其出色。

我们致力于构建安全的 AI，并遵守我们对白宫作出的自愿承诺3。基于此，我们在此分享 GPT‑4o 系统卡，其中包括我们依据防范准备框架⁠（在新窗口中打开）5 进行的评估。在本系统卡中，我们详细介绍了 GPT‑4o 在多个类别的能力、局限性及安全评估情况，重点聚焦于语音到语音（语音）A 能力，同时也对图文能力进行了评估，并阐述了我们为提升安全性和对齐性所采取的措施。此外，我们还纳入了第三方对通用自主功能的评估，以及关于 GPT‑4o 文本和视觉内容功能潜在社会影响的讨论。

##### 2 模型数据与训练
我们利用截至 2023 年 10 月的数据训练 GPT‑4o 的能力，这些数据来源广泛，其中包括：
1. 精选的公开数据：这些数据大多收集自行业标准的机器学习数据集和网络爬虫。
2. 来自**数据合作伙伴的专有数据**。我们通过合作伙伴关系来获取非公开数据，例如付费内容、档案资料和元数据。例如，我们与 Shutterstock 合作⁠（在新窗口中打开）5，共同创作并交付 AI 生成的图像。 

为 GPT‑4o 能力做出贡献的**关键数据集**包括：
1. 网络数据 – 来自*公开网页的数据提供了丰富多样的信息*，确保模型能够学习各种不同的视角和主题。
2. 代码与数学数据 – 在*训练中纳入代码和数学数据，有助于模型通过接触结构化逻辑和问题解决过程，发展出强大的推理能力。*
3. 多模态数据 – 我们*的数据集中包含图像、音频和视频，用于训练 LLM 如何解读输入的非文本内容并生成非文本输出*。
    - 通过这些数据，模型能够学习如何解读真实世界中的视觉图像、动作和序列、语言模式以及语音细微差别。

在部署之前，OpenAI 会评估并缓解生成式模型可能带来的潜在风险，例如信息伤害、偏见与歧视，或其他违反我们安全政策的内容。我们采用了一系列方法，这些方法贯穿了预训练、后训练、产品开发和政策等所有开发阶段。例如，在后训练阶段，我们会让模型与人类偏好保持一致；对生成的模型进行红队测试，并在产品层面添加监控和执行等缓解措施；以及为用户提供内容审核工具和透明度报告。

我们发现，**大部分有效的测试和缓解措施都是在预训练阶段之后进行的**，因为仅通过筛选预训练数据无法解决那些有细微差别的及特定背景下的伤害。
与此同时，*某些预训练阶段的过滤缓解措施可以提供额外的防御层*，加上其他安全缓解措施，有助于从我们的数据集中排除不需要和有害的信息：

我们使用内容审核 API 和安全分类器过滤掉可能导致有害内容或信息危害的数据，包括儿童性虐待材料 (CSAM)、仇恨、暴力内容以及化学、生物、放射及核 (CBRN) 相关信息。 
与我们之前的图像生成系统一样，我们会过滤掉图像生成数据集中的显式内容，如色情图片和儿童性虐待材料。 
我们采用先进的数据过滤流程减少训练数据中的个人信息。
推出 DALL·E 3 时，我们尝试了一种新方法，使用户有权选择不将某些图像用于训练⁠。为了尊重用户的选择，我们对这些图像进行了标记，并使用这些标记从 GPT‑4o 系列模型的训练数据集中移除了所有相关图像实例。

#### OpenAI o1 2024.12（o1-preview 2024.09）
- **强化微调（RFT）**
- **Test-time Scaling**
- 慢思考能力
- 数学、编程能力
- 全面能力提升

我们的大规模强化学习算法在一个数据效率极高的训练过程中，教会模型如何利用其思维链进行富有成效的思考。
我们发现，**随着强化学习（训练时间计算）和思考时间（测试时间计算）的增加，o1 的性能也在不断提高**。
这种方法的扩展限制与 LLM 预训练的限制有很大不同，我们正在继续研究。

##### 1 思维链
与人类在回答难题之前可能会思考很长时间类似，o1 在尝试解决问题时也会使用思维链。
**通过强化学习，o1 可以学会磨练自己的思维链，并完善自己使用的策略。**
- 它学会识别和纠正错误。它学会把棘手的步骤分解成更简单的步骤。它学会在当前方法无效时尝试不同的方法。

这一过程极大地提高了模型的推理能力。为了说明这一飞跃，我们在下面展示了 o1‑preview 在几个难题上的思维链。


#### GPT-4.5 2025.02
- **扩大无监督学习的规模**
- 更强的用户意图执行能力和**更高的“情商”**
- 无需推理即可提高识别模式、建立联系和**生成创造性见解**的能力

我们即将发布迄今为止规模最大、性能最优的聊天模型 — GPT‑4.5 的研究预览版。在扩大训练前和训练后规模方面，GPT‑4.5 又向前迈出了一步。通过扩大无监督学习的规模，GPT‑4.5 无需推理即可提高识别模式、建立联系和生成创造性见解的能力。

早期测试表明，用户与 GPT‑4.5 互动的感觉更自然。凭借更广泛的知识库、更强的用户意图执行能力和更高的“情商”，它在写作润色、编程和解决实际问题等任务中大显身手。另外，它还有望减少幻觉。

##### 1 扩大无监督学习的规模
我们通过**扩大无监督学习和推理这两种互补范式的规模来提高 AI 能力**。它们代表着智力的两个轴心。

1. *无监督学习有助于提高世界模型的准确性和直观性*。GPT‑3.5、GPT‑4 和 GPT‑4.5 等模型推进了这一范式。
2. *另一方面，扩大推理规模⁠有助于教会模型在给出回复之前先行思考并形成思维链，从而帮助它们解决复杂的科学、技术、工程和数学或逻辑问题*。OpenAI o1 和 OpenAI o3‑mini 等模型推进了这一范式。

GPT‑4.5 是通过扩展计算和数据以及架构和优化创新来扩大无监督学习规模的一个例子。GPT‑4.5 在 Microsoft Azure AI 超级计算机上进行了训练。结果表明，该模型拓展了知识面、加深了对世界的了解，进而减少了幻觉并提高了多个主题的回复可靠性。

##### 2 训练与人类协作
随着规模不断扩大，模型能够解决的问题也越来越复杂，而教会它们**更好地理解人类的需求和意图**也因此变得越来越重要。
我们**为 GPT‑4.5 开发了可扩展的新技术，能够利用从较小模型提取的数据来训练规模更大、功能更强的模型**。
这些技术改善了 GPT‑4.5 的可控性、对细微差别的理解能力和自然对话。


##### 3 更强大的推理能力呼之欲出

GPT‑4.5 在给出回复之前不会先行思考，因此具备与 OpenAI o1 等推理模型尤为不同的优势。相较于 OpenAI o1 和 OpenAI o3‑mini 等模型，GPT‑4.5 的通用性更强，而且天生更加智能。我们相信，推理将是未来模型的核心能力，而预训练和推理这两种扩展方法之间将会是相辅相成的关系。随着预训练让 GPT‑4.5 等模型变得更加智能、知识更加渊博，它们将为推理和工具使用智能体奠定更加坚实的基础。


##### GPT-4.1 2025.04
- 1 million 上下文
- 相比4o，提升编码+指令遵循

今天，我们在API中推出了三款新模型：GPT‑4.1、GPT‑4.1 mini和GPT‑4.1 nano。
**这些模型在各方面都优于GPT‑4o和GPT‑4o mini，在编码和指令遵循方面有显著提升**。
它们还拥有更大的上下文窗口——支持多达**1 million**个token的上下文——并且凭借改进的长上下文理解能力，能够更好地利用这些上下文。其知识截止日期已更新至2024年6月。

GPT‑4.1在以下行业标准指标上表现出色：
- 编程方面：GPT-4.1在SWE-bench Verified上的得分为54.6%，相较于GPT-4o绝对提升了21.4%，相较于GPT-4.5绝对提升了26.6%——使其成为编程领域的领先模型。
- 指令遵循：Scale’s MultiChallenge⁠ 基准测试是衡量指令遵循能力的指标，GPT‑4.1的得分是38.3%，比GPT‑4o绝对提高了10.5%。
- 长上下文：Video-MME⁠，作为多模态长上下文理解的基准，GPT‑4.1创下了新的最先进成果——在长时长、无字幕类别中得分72.0%，较GPT‑4o绝对提升6.7%。


#### OpenAI o3 2025.04
- **更大规模强化训练（RFT）**
- **基于强化学习的工具调用能力**
- **首次可结合图像思考**
- 开销约减与效率提升


##### 1 新模型变化
**OpenAI o3 是我们功能最为强大的推理模型，在编码、数学、科学、视觉感知等多个领域均实现了突破。**它在 *Codeforces、SWE-bench（无需构建定制化的特定模型框架）和 MMMU 等基准测试中均取得了新的最优成绩*。该模型非常适合处理需要多维度分析且答案并非显而易见的复杂问题。
- 在视觉任务方面，如分析图像、图表和图形，o3 表现尤为出色。
- 在外部专家的评估中，面对高难度的现实任务，o3 比 OpenAI o1 的重大错误率降低了 20%，尤其在编程、商业/咨询和创意构思等领域表现超群。
- 早期测试者特别指出 o3 作为思考伙伴的分析严谨性，以及其生成和批判性评估新假设的能力，特别是在生物学、数学和工程领域。

**OpenAI o4-mini 是一款更小型但经过优化的模型**，旨在实现快速且经济高效的推理。尽管其规模较小、成本较低，但在数学、编码和视觉任务等方面均拥有卓越的性能。
- 在 AIME 2024 和 2025 的基准测试中，它的表现最为出色。虽然使用计算机可以显著降低 AIME 考试的难度，但我们发现，在 AIME 2025 考试中，当允许 o4-mini 调用 Python 解译器时，其取得了 99.5% pass@1（首次尝试即通过的比例）、100% consensus@8（8 次尝试中的共识正确率）的成绩。虽然这些结果不应与无法调用工具的模型性能直接比较，但凸显出 o4-mini 利用工具的效率；在 AIME 2025 考试中，允许调用工具的 o3 的表现也有类似提升 (98.4% pass@1, 100% consensus@8)。

在专家评估中，o4-mini 在非 STEM 任务以及数据科学等领域也超越了其前身 o3‑mini。得益于其高效率，o4-mini 的使用限制远高于 o3，非常适合用于解决需要推理支持的问题，尤其是高体量、高吞吐量的场景。外部专家评估者认为，这两款模型在指令遵循方面表现出色，提供的回答比其前身更有用、更可验证，这得益于其智能性的提升以及网络资源的整合。与之前的推理模型版本相比，这两款模型的使用体验也更加自然、对话感更强，尤其是它们能够参考记忆和过往对话，使回答更加个性化、更贴合需求。

##### 2 **持续扩展强化学习**
在开发 OpenAI o3 的过程中，我们观察到**大规模强化学习**展现出了与 GPT 系列预训练相同的“**计算量增加 = 性能提升**”的趋势。
- 通过追溯这一扩展路径 — 这次是在强化学习领域 — 我们在训练计算量和推理时推理方面均提高了一个数量级，并且仍然看到了明显的性能提升，这表明模型的性能确实会随着思考时间的增加而持续提高。
- 在保持与 OpenAI o1 相同的延迟和成本的情况下，o3 在 ChatGPT 中展现出了更高的性能，并且我们已经验证，如果允许 o3 进行更长时间的思考，其性能还将持续提升。

此外，我们**还通过强化学习训练这两个模型使用工具 — 不仅教它们如何使用工具，还教它们判断何时使用工具**。它们能够根据期望的结果来部署工具，这使得它们在开放式场景中更加得心应手，特别是在涉及视觉推理和多步骤工作流程的情况下。根据早期测试者的反馈，这种改进在学术基准测试和实际任务中均有所体现。

##### 3 图像思考
现在，这些模型首次能够直接将图像融入其思维链中。它们不仅仅能看到图像，而是能够根据图像进行思考。这开启了一种全新的问题解决方式，将视觉推理和文本推理相结合，在多模态基准测试中展现出了最先进的性能。

用户可以上传白板照片、教材图表或手绘草图，模型能够对其进行解读，即使图像模糊、颠倒或质量较低。借助工具使用，模型还可以在推理过程中实时操作图像，如旋转、缩放或转换图像。

这些模型在视觉感知任务中表现出了最佳性能，能够解决之前难以企及的问题。如需了解更多信息，请查看视觉推理研究博客⁠。（[图像思考](图像思考.md)）

##### 4 自主工具调用
OpenAI o3 和 o4-mini 可以全面访问 ChatGPT 内的工具，以及通过 API 内的函数调用访问您的自定义工具。这些模型经过训练，能够思考如何解决问题，并选择何时以及如何使用工具，以恰当的输出格式快速提供详尽且经过思考的回答（通常在一分钟内）。

#### GPT-5 2025.08
- **统一系统：路由+推理/非推理**
- 减少幻觉、提升指令遵循能力以及减少阿谀奉承
- 常用场景提升性能（写作、编程和医疗）



##### 1 统一系统
GPT‑5 是一个**统一系统**，包含：
1. 一个智能高效的模型（GPT-5-main，前身GPT‑4o），能够回答大多数问题
2. 一个更深入的推理模型（GPT‑5 Thinking，前身OpenAI o3），用于解决更复杂的问题
3. 以及一个实时路由器，能够根据对话类型、复杂度、工具需求以及您的明确意图（例如，如果您在提示中说“认真思考这个问题”）快速决定使用哪个模型。
    - 路由器会持续基于真实信号进行训练，包括用户切换模型、对回复的偏好率以及测量准确性，并随着时间的推移不断优化。

当达到使用限制时，每个模型的精简版本将处理剩余的查询。在不久的将来，我们计划将这些功能整合到一个单一模型中。
- gpt-5-main-mini，前身GPT‑4o-mini
- gpt-5-thinking-mini，前身OpenAI o4-mini
- gpt-5-thinking-nano，前身GPT‑4.1-nano（为开发人员设计）

##### 2 构建更强大、更可靠且更具帮助性的模型
我们在**减少幻觉、提升指令遵循能力以及减少阿谀奉承**方面取得了显著进展
1. 对现实世界问题的更准确回答：GPT‑5 出现*幻觉的可能性比我们之前的模型低得多*。  
    - 在代表 ChatGPT 生产流量的匿名提示上启用网络搜索后，GPT‑5 的回复中包含事实错误的可能性**比GPT‑4o 低约 45%**，而在思考过程中，GPT‑5 的回复中包含事实错误的可能性比 **OpenAI o3 低约 80%**。
    - 我们测量了 GPT‑5 在处理来自两个公开事实性基准的开放式事实查询提示时的幻觉率：LongFact（概念和物体）和 FActScore。 在所有这些基准测试中，“GPT‑5 Thinking”显示出幻觉率的显著下降——大约是 **o3 的六分之一**——这标志着在生成一致准确的长篇内容方面取得了明显的进步。
2. 更诚实的回复
    - 除了事实准确性得到提升外，具备推理功能的 GPT‑5 还会更诚实地向用户说明其操作和能力——尤其是在任务无法完成、定义不明确或缺少关键工具的情况下。为了在训练中获得高奖励，推理模型可能会学会谎称已成功完成任务，或对不确定的答案表现出过分自信。
    - 例如，为了验证这一点，我们从多模态基准 CharXiv 的提示中移除了所有图片，**发现 OpenAI o3 在 86.7% 的情况下仍对不存在的图片给出自信的答案，而 GPT‑5 仅为 9%**。
3. 更安全、更友好的回复
    - 对于 GPT‑5，我们引入了一种新的安全训练形式——安全完成——它教模型在可能的情况下提供最有帮助的答案，同时仍保持在安全边界内。*有时，这可能意味着仅部分回答用户的问题，或仅在高层次上进行回答。*
    - 如果模型需要拒绝回答，GPT‑5 经过训练，能够透明地告知用户拒绝的原因，并提供安全替代方案。在受控实验和我们的生产模型中，我们发现这种方法更为细致，能够*更好地处理双用途问题，对模糊意图具有更强的鲁棒性，并减少不必要的过度拒绝*。
4. 减少阿谀奉承，提升风格
    - 总体而言，GPT‑5 相比 GPT‑4o 表现出**更少的过度讨好倾向，使用更少的无谓表情符号**，并在后续互动中展现出更微妙且富有思考性的表达方式。它应让人感觉更像是与一位*拥有博士级智力的贴心朋友*聊天，而非“与 AI 对话”。

##### 3 评估
同时在 ChatGPT 最常见的三个应用场景中提升了 GPT‑5 的性能：**写作、编程和医疗**。
- 编码：GPT‑5 是我们迄今为止最强大的编码模型。它在**复杂的前端生成和调试大型代码库**方面表现出显著提升。
    - 在 *SWE-bench 验证测试*中达到 74.9%，在 Aider-Polyglot 测试中达到 88%
- 创意表达与写作：GPT‑5 是我们迄今为止最强大的写作助手，能够帮助您将粗略的想法转化为富有文学深度和节奏感的引人入胜的文字。
- 医疗保健：GPT‑5 是我们迄今为止针对医疗保健相关问题表现最佳的模型，它能帮助用户获取健康知识并更好地维护自身健康权益。该模型在我们今年早些时候基于真实场景和医生定义的标准发布的评估工具 **HealthBench⁠ 上，得分显著高于以往任何模型**。
    - 在 *HealthBench Hard 测试*中达到 46.2%
- 数学（在 *AIME 2025 测试*中无需工具即可达到 94.6%）
- 多模态理解（在 *MMMU 测试*中达到 84.2%）