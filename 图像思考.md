# 图像思考
**OpenAI o3 和 o4-mini 是最新的 o 系列视觉推理模型。这是我们的模型第一次能够在思维链中结合图像进行思考，而不仅仅是看到图像。**

与我们早期的 OpenAI o1 模型类似，o3 和 o4-mini 在回答问题前也会进行长时间的思考，并在回答用户问题前调用较长的内部思维链。通过在思维链中结合图像进行思考，o3 和 o4-mini 进一步扩展了这一功能。**图像思考通过使用工具转换用户上传的图像来实现，除了其他简单的图像处理技术外，还允许用户对图像进行裁切、放大和旋转。**更重要的是，这些功能都是原生的，无需依赖单独的专门模型。

ChatGPT 的增强型视觉智能可进行比以往更全面、更准确、更可靠的图像分析，进而帮助您解决更棘手的问题。它能将高级推理与网络搜索和自动缩放、裁切、翻转或图像增强等处理工具无缝结合，甚至能从残缺的照片中获得启发。例如，上传经济学问题集的照片即可获得分步骤解释；分享版本错误的截图就能快速获得根本原因分析。

这种方法实现了*测试时间计算扩展的新轴心，将视觉推理和文本推理无缝融合在一起*。在多模态基准测试中获得的顶尖成绩也反映了这一点，标志着模型向多模态推理迈出了重要一步。

## 视觉推理实操
图像思考允许您以更轻松的方式与 ChatGPT 交互。您可以通过拍照来提问，而不必担心对象的位置，例如文字是否颠倒，或者一张照片中是否存在多个物理问题。即使乍看之下对象并不明显，视觉推理也能促使模型将照片放大，从而看得更清楚。

我们最新的视觉推理模型可与 Python 数据分析、网络搜索、图像生成等其他工具协同工作，从而创造性地有效解决更复杂的问题，同时首次为用户提供多模态代理体验。

## 基准测试表现
为了凸显视觉推理相对于前代多模态模型的改进，我们使用一组不同的人类考试和机器学习基准对 OpenAI o3 和 o4-mini 进行了测试。在我们测试的所有多模态任务中，两款新视觉推理模型的表现明显优于前代模型。

尤其值得注意的是，在我们评估的所有感知基准中，不依赖浏览而进行的图像思考都表现出了显著的提升。在 STEM 相关问题解答 (MMMU、MathVista)、图表阅读与推理 (CharXiv)、感知原语（VLM 为 Blind）和视觉搜索 (V*) 等方面，我们的模型性能达到了新的高度。在 V* 测试中，我们的视觉推理方法达到了 95.7% 的准确率，基本解决了基准问题。